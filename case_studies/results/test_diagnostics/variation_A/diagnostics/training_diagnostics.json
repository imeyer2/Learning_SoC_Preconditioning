{
  "epochs": [
    {
      "epoch": 1,
      "policy_entropy": 7.527274560928345,
      "policy_entropy_per_node": 0.0,
      "advantage_mean": 2.2158706558374752,
      "advantage_std": 1.5945651712059263,
      "advantage_min": -0.6604747702949214,
      "advantage_max": 5.059521833161827,
      "value_explained_var": -0.28731246333188,
      "grad_norm_total": 0.9999995480297132,
      "grad_norm_policy": 0.0,
      "grad_norm_gnn": 0.3553210073781869,
      "grad_max": 0.1116357147693634,
      "attention_entropy": 0.0,
      "node_embedding_mad": 0.0,
      "layer_grad_norms": [
        0.6723889112472534,
        0.5182472467422485,
        0.2475506216287613,
        0.23378446698188782,
        0.2319096326828003,
        0.1986091136932373,
        0.19267208874225616,
        0.13513147830963135,
        0.1201167181134224,
        0.01417353842407465
      ],
      "sparsity_ratio": 0.3629489603024575,
      "selection_entropy": 7.527274560928345,
      "reward_variance": 1.9751522319934782
    },
    {
      "epoch": 2,
      "policy_entropy": 7.520116019248962,
      "policy_entropy_per_node": 0.0,
      "advantage_mean": 0.8767433020336377,
      "advantage_std": 1.4451803185682925,
      "advantage_min": -1.3190285999579574,
      "advantage_max": 2.9106823939676496,
      "value_explained_var": 0.09961941955337072,
      "grad_norm_total": 0.9999998044287175,
      "grad_norm_policy": 0.0,
      "grad_norm_gnn": 0.4155748747292299,
      "grad_max": 0.1121942400932312,
      "attention_entropy": 0.0,
      "node_embedding_mad": 0.0,
      "layer_grad_norms": [
        0.6685512065887451,
        0.5095619559288025,
        0.28524723649024963,
        0.25965794920921326,
        0.2406228631734848,
        0.21289213001728058,
        0.13213859498500824,
        0.09753976762294769,
        0.08179623633623123,
        0.07498191297054291
      ],
      "sparsity_ratio": 0.3629489603024575,
      "selection_entropy": 7.520116019248962,
      "reward_variance": 2.3196259432218524
    },
    {
      "epoch": 3,
      "policy_entropy": 7.517402911186219,
      "policy_entropy_per_node": 0.0,
      "advantage_mean": 0.3253622593848477,
      "advantage_std": 1.50761633520487,
      "advantage_min": -2.020132068314387,
      "advantage_max": 2.7222793777377396,
      "value_explained_var": 0.08977299145197626,
      "grad_norm_total": 0.999999932017906,
      "grad_norm_policy": 0.0,
      "grad_norm_gnn": 0.4123590814282304,
      "grad_max": 0.16512395441532135,
      "attention_entropy": 0.0,
      "node_embedding_mad": 0.0,
      "layer_grad_norms": [
        0.605189323425293,
        0.5067501664161682,
        0.3893626034259796,
        0.28013691306114197,
        0.2697969675064087,
        0.18068791925907135,
        0.15052787959575653,
        0.09768738597631454,
        0.08914311230182648,
        0.027967676520347595
      ],
      "sparsity_ratio": 0.3629489603024575,
      "selection_entropy": 7.517402911186219,
      "reward_variance": 2.497077094869179
    },
    {
      "epoch": 4,
      "policy_entropy": 7.521681642532348,
      "policy_entropy_per_node": 0.0,
      "advantage_mean": -0.040896582716356676,
      "advantage_std": 1.4377262566545939,
      "advantage_min": -2.264450267347017,
      "advantage_max": 2.121163288426213,
      "value_explained_var": 0.0536460923849863,
      "grad_norm_total": 0.9999999353081486,
      "grad_norm_policy": 0.0,
      "grad_norm_gnn": 0.368897209608213,
      "grad_max": 0.12924018502235413,
      "attention_entropy": 0.0,
      "node_embedding_mad": 0.0,
      "layer_grad_norms": [
        0.6128131747245789,
        0.5481112003326416,
        0.31527915596961975,
        0.2636171281337738,
        0.23775087296962738,
        0.23416240513324738,
        0.13803589344024658,
        0.10278960317373276,
        0.09631966799497604,
        0.04913764446973801
      ],
      "sparsity_ratio": 0.3629489603024575,
      "selection_entropy": 7.521681642532348,
      "reward_variance": 2.1842323177841525
    },
    {
      "epoch": 5,
      "policy_entropy": 7.518460750579834,
      "policy_entropy_per_node": 0.0,
      "advantage_mean": 0.0049744333885273885,
      "advantage_std": 1.4565957658149538,
      "advantage_min": -2.192329197744902,
      "advantage_max": 2.184332470269364,
      "value_explained_var": 0.05258948354543047,
      "grad_norm_total": 0.9999999303274217,
      "grad_norm_policy": 0.0,
      "grad_norm_gnn": 0.44041033783331757,
      "grad_max": 0.15482312440872192,
      "attention_entropy": 0.0,
      "node_embedding_mad": 0.0,
      "layer_grad_norms": [
        0.574878454208374,
        0.49533990025520325,
        0.4394392669200897,
        0.29606688022613525,
        0.28980153799057007,
        0.15681251883506775,
        0.11177971959114075,
        0.0855095386505127,
        0.07242228835821152,
        0.0603640191257
      ],
      "sparsity_ratio": 0.3629489603024575,
      "selection_entropy": 7.518460750579834,
      "reward_variance": 2.2394423411403945
    }
  ]
}